{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a20f89d-a1f1-4b72-81e7-b25cdc74c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import spacy\n",
    "import torch.nn as nn\n",
    "from anchor import anchor_text\n",
    "import pickle\n",
    "from myUtils import *\n",
    "from transformer.utils import *\n",
    "from dataset.dataset_loader import *\n",
    "import transformer.training as training\n",
    "import transformer.plot as plot\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebd08be-6323-4838-b3eb-cd8ccddf6126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1cb523-637b-4f89-8bef-d52e80f301d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in training samples: 3307\n",
      "Number of tokens in training labels: 2\n"
     ]
    }
   ],
   "source": [
    "review_parser, label_parser, ds_train, ds_valid, ds_test = create_sentiment_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6a2143-b2fb-4238-b520-75bae280a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_examples = pickle.load( open( \"results/transformer_anchor_examples.pickle\", \"rb\" ))\n",
    "explanations = pickle.load(open( \"results/gru_extended_counter_exps.pickle\", \"rb\" ))\n",
    "#explanations = [exp for exp in explanations if len(exp.fit_examples)] \n",
    "predictions = pickle.load(open( \"results/gru_train_predictions.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa0c675c-1886-44ec-8f98-78adaf72086c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-0.9670, device='cuda:0', requires_grad=True),\n",
       " tensor(-0.8306, device='cuda:0', requires_grad=True),\n",
       " tensor(0.7846, device='cuda:0', requires_grad=True),\n",
       " tensor(0.5805, device='cuda:0', requires_grad=True),\n",
       " tensor(-0.8827, device='cuda:0', requires_grad=True),\n",
       " tensor(-0.7858, device='cuda:0', requires_grad=True),\n",
       " tensor(0.7640, device='cuda:0', requires_grad=True),\n",
       " tensor(-0.6994, device='cuda:0', requires_grad=True),\n",
       " tensor(-0.8751, device='cuda:0', requires_grad=True),\n",
       " tensor(-0.9215, device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "503de3a2-c060-4964-9131-6610a49d6162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d334b0b-2021-4287-9073-8163dd832306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def get_occurences(ds):\n",
    "    c = Counter()\n",
    "    ignore = list(\".,- \\'\\\"\\s[]?():!;\")\n",
    "    ignore.extend([\"--\", \"'s\"])\n",
    "    ignore.extend(stopwords.words('english'))\n",
    "    for ds_example in ds:\n",
    "        c.update(ds_example.text)\n",
    "    for ignore_s in ignore:\n",
    "        del c[ignore_s]\n",
    "    values = np.array(list(c.values())).reshape(-1,1)\n",
    "    scaler = MinMaxScaler().fit(values)\n",
    "    for word in c.keys():\n",
    "        c[word] = scaler.transform([[c[word]]])[0][0] + 1e-5\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2884a892-8835-40db-86a9-1f56edd8c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_distribution(ds):\n",
    "    c_pos = Counter()\n",
    "    c_neg = Counter()\n",
    "    c = Counter()\n",
    "    ignore = list(\".,- \\'\\\"\\s[]?():!;\")\n",
    "    ignore.extend([\"--\", \"'s\"])\n",
    "    ignore.extend(stopwords.words('english'))\n",
    "    \n",
    "    for ds_example in ds:\n",
    "        if ds_example.label == 'positive':\n",
    "            c_pos.update(set(ds_example.text))\n",
    "        else:\n",
    "            c_neg.update(set(ds_example.text))\n",
    "\n",
    "    all_words = list(c_pos.keys())\n",
    "    all_words.extend(c_neg.keys())\n",
    "    all_words = set(all_words)\n",
    "    for word in all_words:\n",
    "        c[word] = (c_pos[word]-c_neg[word])/(c_pos[word]+c_neg[word])\n",
    "    for ignore_s in ignore:\n",
    "        c[ignore_s]=0\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9169d9ee-614e-4341-b04f-28204b0858b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_distribution(ds, predictions):\n",
    "    d = defaultdict(list)\n",
    "    ignore = list(\".,- \\'\\\"\\s[]?():!;\")\n",
    "    ignore.extend([\"--\", \"'s\"])\n",
    "    ignore.extend(stopwords.words('english'))\n",
    "    \n",
    "    for ds_example, prediction in zip(ds, predictions):\n",
    "        for word in ds_example.text:\n",
    "            d[word].append(prediction)\n",
    "\n",
    "    prediction_dict = defaultdict(lambda: 0.0)\n",
    "    \n",
    "    for word, values in d.items():\n",
    "        prediction_dict[word] = sum(values)/len(values)\n",
    "    for ignore_s in ignore:\n",
    "        prediction_dict[ignore_s]=0.0\n",
    "    \n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537a43ea-fd27-4f10-a7b8-c3f38bae6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = get_label_distribution(ds_train)\n",
    "occurences = get_occurences(ds_train)\n",
    "prediction_dist = get_prediction_distribution(ds_train, predictions)\n",
    "statistics = [label_distribution, occurences, prediction_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54018a00-cf3c-4074-9983-e34acd0db992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def generate_example(ds, anchor_examples, explanations):\n",
    "    filtered_examples = []\n",
    "    for example in ds:\n",
    "        for exp in explanations:     \n",
    "            if ' '.join(example.text)==anchor_examples[exp.index]:\n",
    "                c_example = copy.deepcopy(example)\n",
    "                if exp.test_precision < 0.5:\n",
    "                    c_example.label = 'negative'\n",
    "                else:\n",
    "                     c_example.label = 'positive'\n",
    "                filtered_examples.append(c_example)\n",
    "                \n",
    "                break\n",
    "                \n",
    "    return filtered_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b77346fe-e0a3-4a52-a28d-e1069c3da581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def generate_example(ds, anchor_examples, explanations):\n",
    "    filtered_examples = []\n",
    "    for example in ds:\n",
    "        for exp in explanations:     \n",
    "            if ' '.join(example.text)==anchor_examples[exp.index]:\n",
    "                c_example = copy.deepcopy(example)\n",
    "                if exp.test_precision < 0.5:\n",
    "                    c_example.label = 0\n",
    "                else:\n",
    "                    c_example.label = 2*(exp.test_precision - 0.5)\n",
    "             \n",
    "                filtered_examples.append(c_example)\n",
    "                \n",
    "                break\n",
    "                \n",
    "    return filtered_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97283e7f-a53c-4982-8d3c-c4c8fea20143",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = generate_example(ds_train, anchor_examples, explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b13636db-2927-43dd-b5c5-ef625dbe5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(examples)\n",
    "train_size = round(0.75*size)\n",
    "ds_train.examples = examples[:train_size]\n",
    "ds_valid.examples = examples[train_size:]\n",
    "ds_test = ds_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78d128-2248-4eab-b7f6-cbb9b533d70b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248ab89a-b9e9-4ad1-af80-7b3a898990b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(examples, name):\n",
    "    text = [' '.join(example.text) for example in examples]\n",
    "    label = [example.label for example in examples]\n",
    "    pd.DataFrame({'review': text, 'label': label}).to_csv(f'dataset/hugging/{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0c083d-829c-434d-9dae-c8c0590dd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(train_examples, 'train')\n",
    "save_to_csv(valid_examples, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b4787-ee97-413b-bb13-fd68ef1dfa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.huggingUtils import *\n",
    "set_seed()\n",
    "model = load_model('roberta-base')\n",
    "data = load_data('dataset/hugging', 'dataset/hugging')\n",
    "tokenized_data = tokenize_dataset(data, tokenizer_name='roberta-base')\n",
    "train(model, tokenized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7100fb-1e20-4880-b9f7-9de5c4c613de",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "472f4329-be47-4423-b2ff-60160e224ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import sys\n",
    "def forward_dl(model, dl, device, type_dl):\n",
    "    model.train(False)\n",
    "    num_samples = len(dl) * dl.batch_size\n",
    "    num_batches = len(dl)  \n",
    "    pbar_name = type(model).__name__\n",
    "    list_y_real = []\n",
    "    list_y_pred = []\n",
    "    pbar_file = sys.stdout\n",
    "    num_correct = 0\n",
    "    dl_iter = iter(dl)\n",
    "    for batch_idx in range(num_batches):\n",
    "        data = next(dl_iter)\n",
    "        x, y = data.text, data.label\n",
    "        list_y_real.append(y)\n",
    "        x = x.to(device)  # (S, B, E)\n",
    "        y = y.to(device)  # (B,)\n",
    "        with torch.no_grad():\n",
    "            if isinstance(model, models.VanillaGRU):\n",
    "                y_pred_log_proba = model(x)\n",
    "            elif isinstance(model, models.MultiHeadAttentionNet):\n",
    "                y_pred_log_proba, _ = model(x)\n",
    "            y_pred = torch.argmax(y_pred_log_proba, dim=1)\n",
    "            num_correct += torch.sum(y_pred == y).float().item()\n",
    "            list_y_pred.append(y_pred)\n",
    "    accuracy = 100.0 * num_correct / num_samples\n",
    "    print(f'Accuracy for {type_dl} is {accuracy}')\n",
    "    \n",
    "    all_y_real = torch.cat(list_y_real)\n",
    "    all_y_pred = torch.cat(list_y_pred)\n",
    "    return all_y_real, all_y_pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb6dc1ff-4ae3-447e-853f-0bb5f59365ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_for_csv():\n",
    "    classes = None\n",
    "    if type_dataset == 'trinary':\n",
    "        classes = ['positive', 'negative', 'neutral']\n",
    "    elif type_dataset == 'binary':\n",
    "        classes = ['positive', 'negative']\n",
    "    elif type_dataset == 'fine_grained':\n",
    "        classes = ['positive', 'negative', 'neutral', 'very_positive', 'very_negative']\n",
    "    index_csv = [f'pred_{curr_class}' for curr_class in classes]\n",
    "    columns_csv = [f'real_{curr_class}' for curr_class in classes]\n",
    "    return classes, index_csv, columns_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6dd33c7-8839-46b1-a97b-138aca07227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_confusion_matrix(y_real, y_pred, model_name, type_dl):\n",
    "    classes, index_csv, columns_csv = get_classes_for_csv()\n",
    "    num_classes = len(classes)\n",
    "    num_classes_in_y = len(torch.unique(y_real))\n",
    "    assert num_classes == num_classes_in_y, 'Mismatch in number of classes'\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "            all_pred_classes = y_pred[y_real == class_index]\n",
    "            curr_col = torch.histc(all_pred_classes, bins=num_classes, min=0, max=num_classes - 1)\n",
    "            confusion_matrix[:, class_index] = curr_col\n",
    "    confusion_matrix = confusion_matrix.numpy()\n",
    "    df = pd.DataFrame(confusion_matrix, index = index_csv, columns = columns_csv, dtype=int)\n",
    "    #df.to_csv(output_directory / str('confusion_matrix_' + model_name + '_' + type_dl + '.csv'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f56b614-9489-42b4-90c0-39de13795316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "def train_model(model_name, device, output_directory = 'results', task = 'classification'):\n",
    "    NUM_EPOCHS = 100\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    hp = load_hyperparams(model_name, type_dataset)\n",
    "    if task == 'regression':\n",
    "        hp['output_classes'] = 1\n",
    "        loss_fn = nn.MSELoss()\n",
    "        \n",
    "    if model_name == 'gru':\n",
    "        model = models.VanillaGRU(review_parser.vocab, hp['embedding_dim'], hp['hidden_dim'], hp['num_layers'], hp['output_classes'], hp['dropout'], statistics, task == 'regression').to(device)\n",
    "    elif model_name == 'attention':\n",
    "        model = models.MultiHeadAttentionNet(input_vocabulary=review_parser.vocab, embed_dim=hp['embedding_dim'], num_heads=hp['num_heads'], \n",
    "                                           dropout=hp['dropout'], two_attention_layers=hp['two_atten_layers'], output_classes=hp['output_classes']).to(device)\n",
    "    print(model)\n",
    "\n",
    "    dl_train, dl_valid, dl_test = torchtext.legacy.data.BucketIterator.splits((ds_train, ds_valid, ds_test), batch_size=hp['batch_size'], sort = False, shuffle=False, device=device)\n",
    " \n",
    "    optimizer = optim.Adam(model.parameters(), lr=hp['lr'])\n",
    "    \n",
    "    trainer = training.SentimentTrainer(model, loss_fn, optimizer, device)\n",
    "    checkpoint_filename = str(output_directory) +  '/' + model_name\n",
    "    print(f'Saving checkpoint with prefix: {checkpoint_filename}')\n",
    "    fit_res = trainer.fit(dl_train, dl_valid, NUM_EPOCHS, early_stopping = hp['early_stopping'], checkpoints = checkpoint_filename, params = hp)\n",
    "\n",
    "    fig, axes = plot.plot_fit(fit_res)\n",
    "    fig.savefig(output_directory + '/' + str(model_name + '.png'))\n",
    "    saved_state = torch.load(checkpoint_filename + '.pt', map_location=device)\n",
    "    model.load_state_dict(saved_state[\"model_state\"])\n",
    "    loaded_hp = saved_state[\"parameters\"]\n",
    "    print('----- Loaded params ------')\n",
    "    print(loaded_hp)\n",
    "    if task == 'classification':\n",
    "        all_dataloaders = [dl_train, dl_valid, dl_test]\n",
    "        type_dls = ['train', 'valid', 'test']\n",
    "        accuracies = []\n",
    "        for dl, type_dl in zip(all_dataloaders, type_dls):\n",
    "            y_real, y_pred, accuracy = forward_dl(model, dl, device, type_dl)\n",
    "            df = compute_confusion_matrix(y_real, y_pred, model_name, type_dl)\n",
    "            accuracies.append(accuracy)\n",
    "            display(df)\n",
    "        numpy_accuracy = np.array(accuracies)\n",
    "        df = pd.DataFrame(numpy_accuracy, index = type_dls, dtype=float)\n",
    "        df.to_csv(output_directory + '/' + str('accuracies_' + model_name + '.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044df00-2917-4d34-93c3-d1b01d1fb2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 100, 'batch_size': 32, 'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0005, 'early_stopping': 20, 'output_classes': 2}\n",
      "VanillaGRU(\n",
      "  (embedding_layer): Embedding(3307, 103)\n",
      "  (GRU_layer): GRU(103, 256, num_layers=2, dropout=0.3)\n",
      "  (dropout_layer): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n",
      "Saving checkpoint with prefix: results/gru\n",
      "--- EPOCH 1/100 ---\n",
      "train_batch (Avg. Loss 0.191, R2 -0.480): 100%|█| 19/19 [00:00<00:00, 109.16it/s\n",
      "test_batch (Avg. Loss 0.153, R2 -0.068): 100%|███| 7/7 [00:00<00:00, 315.50it/s]\n",
      "*** Saved checkpoint results/gru.pt at epoch 1\n",
      "--- EPOCH 2/100 ---\n",
      "train_batch (Avg. Loss 0.141, R2 -0.070): 100%|█| 19/19 [00:00<00:00, 131.08it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.062): 100%|███| 7/7 [00:00<00:00, 322.24it/s]\n",
      "*** Saved checkpoint results/gru.pt at epoch 2\n",
      "--- EPOCH 3/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.056): 100%|█| 19/19 [00:00<00:00, 139.46it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.048): 100%|███| 7/7 [00:00<00:00, 329.99it/s]\n",
      "*** Saved checkpoint results/gru.pt at epoch 3\n",
      "--- EPOCH 4/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.058): 100%|█| 19/19 [00:00<00:00, 141.71it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.051): 100%|███| 7/7 [00:00<00:00, 330.71it/s]\n",
      "--- EPOCH 5/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.075): 100%|█| 19/19 [00:00<00:00, 138.21it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.053): 100%|███| 7/7 [00:00<00:00, 321.82it/s]\n",
      "--- EPOCH 6/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.064): 100%|█| 19/19 [00:00<00:00, 139.87it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.055): 100%|███| 7/7 [00:00<00:00, 331.90it/s]\n",
      "--- EPOCH 7/100 ---\n",
      "train_batch (Avg. Loss 0.139, R2 -0.063): 100%|█| 19/19 [00:00<00:00, 140.75it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.051): 100%|███| 7/7 [00:00<00:00, 346.52it/s]\n",
      "--- EPOCH 8/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.072): 100%|█| 19/19 [00:00<00:00, 141.01it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.052): 100%|███| 7/7 [00:00<00:00, 336.06it/s]\n",
      "--- EPOCH 9/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.060): 100%|█| 19/19 [00:00<00:00, 139.92it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.050): 100%|███| 7/7 [00:00<00:00, 342.98it/s]\n",
      "--- EPOCH 10/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.055): 100%|█| 19/19 [00:00<00:00, 135.61it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.060): 100%|███| 7/7 [00:00<00:00, 336.96it/s]\n",
      "--- EPOCH 11/100 ---\n",
      "train_batch (Avg. Loss 0.140, R2 -0.047): 100%|█| 19/19 [00:00<00:00, 139.30it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.049): 100%|███| 7/7 [00:00<00:00, 339.59it/s]\n",
      "--- EPOCH 12/100 ---\n",
      "train_batch (Avg. Loss 0.139, R2 -0.050): 100%|█| 19/19 [00:00<00:00, 140.41it/s\n",
      "test_batch (Avg. Loss 0.152, R2 -0.055): 100%|███| 7/7 [00:00<00:00, 326.13it/s]\n",
      "--- EPOCH 13/100 ---\n",
      "train_batch (0.139):  89%|██████████████████▊  | 17/19 [00:00<00:00, 132.67it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(\"results/gru.pt\"):\n",
    "    os.remove(\"results/gru.pt\")\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "training.regression = True\n",
    "train_model('gru', device, task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ec7239e-6617-4b54-9627-083825194c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_true = [1, 2, 3]\n",
    "y_pred = [1, 2, 3]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a0337-1eef-4ba1-be8a-ee197430b42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5073ae0a-f2d7-4f9e-95c1-3353fef4304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from dataset_loader import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from retrain_utils import *\n",
    "\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07fc3de-eb19-4f46-bb94-6ad8a334e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84233b20-0199-43d1-908f-ad12c15856c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'sentiment'\n",
    "ds = get_ds(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d98a99-db2e-47d9-b3ce-4a6de2117178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name ='google/electra-small-discriminator'\n",
    "model_name =  'huawei-noah/TinyBERT_General_4L_312D'\n",
    "folder_name = 'tinybert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584a1b5d-bee9-492f-baa8-5da7ead5f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_df = retrainUtils(model_name, dataset_name).replace_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c88a30a-c910-4ffe-bfb2-ecd2aca8a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.concat([ds['train'].to_pandas(), replaced_df], ignore_index=True)\n",
    "ds['train'] = Dataset.from_pandas(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2f18f6-83bb-4ddf-84b4-29ff989f14c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForSequenceClassification: ['fit_denses.3.weight', 'cls.predictions.decoder.weight', 'fit_denses.2.bias', 'fit_denses.0.bias', 'fit_denses.1.weight', 'fit_denses.1.bias', 'fit_denses.0.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'fit_denses.3.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'fit_denses.4.weight', 'fit_denses.2.weight', 'fit_denses.4.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485d39f8a17f4406a1abaae112bb8ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9777 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd484f9c2c148619bcac7a1b2010dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2087 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9777\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3060/3060 01:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397804</td>\n",
       "      <td>0.823191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.396811</td>\n",
       "      <td>0.822233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.404085</td>\n",
       "      <td>0.841878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.458214</td>\n",
       "      <td>0.843316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.490111</td>\n",
       "      <td>0.838524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.493688</td>\n",
       "      <td>0.839483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.664571</td>\n",
       "      <td>0.836128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.703238</td>\n",
       "      <td>0.837087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.748798</td>\n",
       "      <td>0.840920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.774139</td>\n",
       "      <td>0.834691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-306\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-306/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-612\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-612/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-612/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-918\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-918/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-918/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1224\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1224/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1224/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1530\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1530/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1836\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1836/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1836/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-2142\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-2142/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-2142/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-2448\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-2448/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-2448/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-2754\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-2754/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-2754/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-3060\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-3060/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-3060/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from tinybert/sentiment/check/checkpoint-1224 (score: 0.8433157642549114).\n",
      "Configuration saved in tinybert/sentiment/updated_model/config.json\n",
      "Model weights saved in tinybert/sentiment/updated_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = load_model(model_name)\n",
    "tokenized_data = tokenize_dataset(ds, tokenizer_name=model_name, max_length = 64)\n",
    "train(model, tokenized_data, path=f'{folder_name}/{dataset_name}/check', num_train_epochs=10)\n",
    "model.save_pretrained(f'{folder_name}/{dataset_name}/updated_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9268212b-573e-4c5e-89eb-d307592929cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62da0dc-ebbf-4e35-b7db-f22dcb916fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sentences(sentences):\n",
    "    encoded = [[101] +[tokenizer._convert_token_to_id_with_added_voc(token) for token in tokens] + [102]         \n",
    "               for tokens in sentences]\n",
    "    #encoded = tokenizer.encode(sentences, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    to_pred = torch.tensor(encoded, device=device)\n",
    "    outputs = traced_model(to_pred)[0]\n",
    "    print(outputs)\n",
    "    return torch.argmax(outputs, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99a4ca-1d2a-458e-aa4d-a4c7c8cfe4c5",
   "metadata": {},
   "source": [
    "### save best model's folder as 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74521277-10e9-42c5-a715-3a3bc0e826ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file tinybert/sentiment/model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"tinybert/sentiment/model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"structure\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"torchscript\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file tinybert/sentiment/model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at tinybert/sentiment/model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f'{folder_name}/{dataset_name}/model', num_labels=2, torchscript=True).to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92cc4e8-82e3-419e-b15b-f1ef52d5e866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f969430d5542539c33598948122e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8346 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86334dbade384a74b36e4cbbcc00a185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2087 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = tokenize_dataset(ds, tokenizer_name=model_name, max_length = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f22324e4-dce5-484a-a774-8aa36cf41c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8346\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [261/261 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2261132448911667,\n",
       " 'eval_accuracy': 0.917685118619698,\n",
       " 'eval_runtime': 3.2137,\n",
       " 'eval_samples_per_second': 2597.032,\n",
       " 'eval_steps_per_second': 81.216}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, tokenized_data, path=f'{folder_name}/{dataset_name}', evaluate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b253f7ff-c27c-491c-aaac-d0f8f5a26bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"i love movies\", add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "traced_model = torch.jit.trace(model, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a00a2b6-d259-4a44-88ef-40d00e072a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(traced_model, f\"{folder_name}/{dataset_name}/traced.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33502fa4-fc95-4cfb-926b-7196433f58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.load(f\"{folder_name}/{dataset_name}/traced.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff792ff7-f7db-420c-b49b-e4f869980a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1096, -2.0074]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences([tokenizer.tokenize(\"i hate movies\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a217a8a2-8af5-46ee-a31c-9ece74b0833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4865,  2.3588]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences([tokenizer.tokenize(\"i love movies\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

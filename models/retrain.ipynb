{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5073ae0a-f2d7-4f9e-95c1-3353fef4304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from dataset_loader import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07fc3de-eb19-4f46-bb94-6ad8a334e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84233b20-0199-43d1-908f-ad12c15856c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'offensive'\n",
    "ds = get_ds(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d98a99-db2e-47d9-b3ce-4a6de2117178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name ='google/electra-small-discriminator'\n",
    "model_name =  'huawei-noah/TinyBERT_General_4L_312D'\n",
    "folder_name = 'tinybert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca80ed-2038-4be9-9987-feeb0160f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker = pipeline('fill-mask', model='distilbert-base-uncased')\n",
    "sentences = [tokenizer.tokenize(s) for i, s in enumerate(sentences) if labels[i]==desired_label]\n",
    "def _replace_tokens(self, removed_tokens, sentences):\n",
    "    replaced_sentences = []\n",
    "    for s in sentences:\n",
    "        tokenized_sentence = copy.deepcopy(s)\n",
    "        for i in range(len(tokenized_sentence)):\n",
    "            token = tokenized_sentence[i]\n",
    "            if token in removed_tokens:\n",
    "                tokenized_sentence[i] = '[MASK]'\n",
    "                sentence = self.tokenizer.decode(self.tokenizer.encode(tokenized_sentence))\n",
    "                results = self.unmasker(sentence, top_k=2)\n",
    "                for r in results:\n",
    "                    if r['token_str']!=token:\n",
    "                        tokenized_sentence[i] = r['token_str']\n",
    "                        break\n",
    "\n",
    "        replaced_sentences.append(tokenized_sentence)\n",
    "    return replaced_sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f18f6-83bb-4ddf-84b4-29ff989f14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = load_model(model_name)\n",
    "tokenized_data = tokenize_dataset(ds, tokenizer_name=model_name, max_length = 64)\n",
    "train(model, tokenized_data, path=f'{folder_name}/{dataset_name}', num_train_epochs=10)\n",
    "model.save_pretrained(f'{folder_name}/{dataset_name}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9268212b-573e-4c5e-89eb-d307592929cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/almr16/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/vocab.txt from cache at /home/almr16/.cache/huggingface/transformers/4ec675a1f3cd38f2ddbe71010ce58471a710dd0188687381cf6f06fa7860c86a.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/almr16/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D/resolve/main/config.json from cache at /home/almr16/.cache/huggingface/transformers/740f3ffeb47194ea97e78563af6f51d8fce8d8346d36d41889c75780869cf609.71ad48e6ad371e0c3ffa4982a5cc1c97e41023678e120b71ebe50addd42ec567\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62da0dc-ebbf-4e35-b7db-f22dcb916fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sentences(sentences):\n",
    "    encoded = [[101] +[tokenizer._convert_token_to_id_with_added_voc(token) for token in tokens] + [102]         \n",
    "               for tokens in sentences]\n",
    "    #encoded = tokenizer.encode(sentences, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    to_pred = torch.tensor(encoded, device=device)\n",
    "    outputs = traced_model(to_pred)[0]\n",
    "    print(outputs)\n",
    "    return torch.argmax(outputs, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99a4ca-1d2a-458e-aa4d-a4c7c8cfe4c5",
   "metadata": {},
   "source": [
    "### save best model's folder as 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74521277-10e9-42c5-a715-3a3bc0e826ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file tinybert/offensive/model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"tinybert/offensive/model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"structure\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"torchscript\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file tinybert/offensive/model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at tinybert/offensive/model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f'{folder_name}/{dataset_name}/updated_model', num_labels=2, torchscript=True).to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b253f7ff-c27c-491c-aaac-d0f8f5a26bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"i love movies\", add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "traced_model = torch.jit.trace(model, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a00a2b6-d259-4a44-88ef-40d00e072a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(traced_model, f\"{folder_name}/{dataset_name}/traced.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33502fa4-fc95-4cfb-926b-7196433f58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.load(f\"{folder_name}/{dataset_name}/traced.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff792ff7-f7db-420c-b49b-e4f869980a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1096, -2.0074]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences([tokenizer.tokenize(\"i hate movies\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a217a8a2-8af5-46ee-a31c-9ece74b0833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4865,  2.3588]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences([tokenizer.tokenize(\"i love movies\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b042376-70a4-4a2f-a790-260c1ddc49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824450e8-4375-46d1-8b2d-0404b893636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when apply torchscript to models sometimes\n",
    "torch._C._jit_set_texpr_fuser_enabled(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5073ae0a-f2d7-4f9e-95c1-3353fef4304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from dataset_loader import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "from retrain_utils import *\n",
    "\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07fc3de-eb19-4f46-bb94-6ad8a334e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84233b20-0199-43d1-908f-ad12c15856c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'corona'\n",
    "ds = get_ds(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d98a99-db2e-47d9-b3ce-4a6de2117178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =  'huawei-noah/TinyBERT_General_4L_312D'\n",
    "folder_name = 'tinybert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cdba04-5454-4e4a-b342-55642be698f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_utils = RetrainUtils(model_name, dataset_name)\n",
    "added_train = retrain_utils.replace_sentences(ds['train'].to_pandas(), RetrainAction.ADD)\n",
    "removed_train = retrain_utils.replace_sentences(ds['train'].to_pandas(), RetrainAction.REMOVE)\n",
    "replaced_train = retrain_utils.replace_sentences(ds['train'].to_pandas(), RetrainAction.REPLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5123865d-c0ce-4674-8e69-8a6c206e24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = removed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e93b34-b8ee-4341-9db9-238683e199af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice is is train to test\n",
    "ds['test'] = get_ds('counter')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea2f18f6-83bb-4ddf-84b4-29ff989f14c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/almr16/.cache/huggingface/hub/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/almr16/.cache/huggingface/hub/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/pytorch_model.bin\n",
      "Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'fit_denses.0.bias', 'fit_denses.2.bias', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'fit_denses.4.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'fit_denses.1.weight', 'cls.predictions.transform.dense.bias', 'fit_denses.3.bias', 'fit_denses.2.weight', 'fit_denses.1.bias', 'fit_denses.0.weight', 'fit_denses.4.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /home/almr16/.cache/huggingface/hub/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/almr16/.cache/huggingface/hub/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /home/almr16/.cache/huggingface/hub/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/almr16/.cache/huggingface/hub/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"huawei-noah/TinyBERT_General_4L_312D\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1200,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb1e894e0cc4d85adfdb2e87870164e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8346 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe02e87726cc45559514cb2361cf9c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2087 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "***** Running training *****\n",
      "  Num examples = 8346\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2610\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2610' max='2610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2610/2610 01:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.402541</td>\n",
       "      <td>0.819358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.390127</td>\n",
       "      <td>0.828941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.433905</td>\n",
       "      <td>0.826066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>0.836128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.497425</td>\n",
       "      <td>0.833733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.550619</td>\n",
       "      <td>0.829420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.829420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.709996</td>\n",
       "      <td>0.834212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.792050</td>\n",
       "      <td>0.833733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.806836</td>\n",
       "      <td>0.833733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-261\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-261/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-261/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-522\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-522/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-522/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-783\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-783/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-783/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1044\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1044/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1044/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1305\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1305/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1305/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1566\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1566/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1566/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-1827\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-1827/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-1827/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-2088\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-2088/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-2088/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-2349\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-2349/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-2349/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to tinybert/sentiment/check/checkpoint-2610\n",
      "Configuration saved in tinybert/sentiment/check/checkpoint-2610/config.json\n",
      "Model weights saved in tinybert/sentiment/check/checkpoint-2610/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from tinybert/sentiment/check/checkpoint-1044 (score: 0.8361284139913752).\n",
      "Configuration saved in tinybert/sentiment/normal_model/config.json\n",
      "Model weights saved in tinybert/sentiment/normal_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = load_model(model_name)\n",
    "tokenized_data = tokenize_dataset(ds, tokenizer_name=model_name, max_length = 64)\n",
    "train(model, tokenized_data, path=f'{folder_name}/{dataset_name}/check', num_train_epochs=10)\n",
    "model.save_pretrained(f'{folder_name}/{dataset_name}/updated_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9268212b-573e-4c5e-89eb-d307592929cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c62da0dc-ebbf-4e35-b7db-f22dcb916fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sentences(sentences, m):\n",
    "    encoded = [[101] +[tokenizer._convert_token_to_id_with_added_voc(token) for token in tokens] + [102]         \n",
    "               for tokens in sentences]\n",
    "    to_pred = torch.tensor(encoded, device=device)\n",
    "    outputs = m(to_pred)[0]\n",
    "    print(outputs)\n",
    "    return torch.argmax(outputs, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99a4ca-1d2a-458e-aa4d-a4c7c8cfe4c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### save best model's folder as 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74521277-10e9-42c5-a715-3a3bc0e826ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f'{folder_name}/{dataset_name}/updated_model', num_labels=2, torchscript=True).to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92cc4e8-82e3-419e-b15b-f1ef52d5e866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244b15b9197440bd9e2bd4be3d9385a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dc90c9d9474236bf4df369cfc059b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = tokenize_dataset(ds, tokenizer_name=model_name, max_length = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22324e4-dce5-484a-a774-8aa36cf41c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2887853682041168,\n",
       " 'eval_accuracy': 0.8835,\n",
       " 'eval_runtime': 0.7599,\n",
       " 'eval_samples_per_second': 2631.893,\n",
       " 'eval_steps_per_second': 82.905}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, tokenized_data, path=f'{folder_name}/{dataset_name}', evaluate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe70a78-df2e-4a46-852e-468885bf9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(torch.nn.Module):\n",
    "    def __init__(self, m1, m2, threshold):\n",
    "        super(Council, self).__init__()\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = self.m1(x)[0]\n",
    "        scores = self.softmax(outputs)\n",
    "        if torch.max(scores, 1).values.item() > self.threshold:\n",
    "            return torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        outputs = self.m2(x)[0]\n",
    "        return torch.argmax(outputs, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa16e9f-50c2-4bee-86df-426c4040a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(m, test):\n",
    "    labels = list(map(int, test['label']))\n",
    "    sentences = [tokenizer(s)['input_ids'] for s in test['text']]\n",
    "    sentences = [torch.tensor([s], device = device) for s in sentences]\n",
    "    predictions = [m(sentence) for sentence in sentences]\n",
    "    return sum(p==l for l, p in zip(predictions, labels))/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5836254-3b70-4517-99d0-1f3d9bd14d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = AutoModelForSequenceClassification.from_pretrained(f'{folder_name}/{dataset_name}/model', num_labels=2, torchscript=True).to(device)\n",
    "model2 = model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f747a2c2-c160-47d9-a88c-ff0ca3a0c7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ths = [0.0, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 0.96, 0.97, 0.98, 0.99, 0.993, 0.995, 0.997, 1]\n",
    "accs = []\n",
    "for th in ths:\n",
    "    ensemble = Ensemble(model, model2, th)\n",
    "    acc = calc_accuracy(ensemble, ds['test'])[0]\n",
    "    accs.append(acc)\n",
    "_ = plt.scatter(ths, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b67e97-8023-4e70-988a-76377c5ab20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ths = [0.0, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 0.96, 0.97, 0.98, 0.99, 0.993, 0.995, 0.997, 1]\n",
    "accs = []\n",
    "for th in ths:\n",
    "    ensemble = Ensemble(model, model2, th)\n",
    "    acc = calc_accuracy(ensemble, ds['test'])[0]\n",
    "    accs.append(acc)\n",
    "_ = plt.scatter(ths, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b253f7ff-c27c-491c-aaac-d0f8f5a26bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"i love movies\", add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "traced_model = torch.jit.trace(model, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a00a2b6-d259-4a44-88ef-40d00e072a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(traced_model, f\"{folder_name}/{dataset_name}/traced_m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33502fa4-fc95-4cfb-926b-7196433f58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.load(f\"{folder_name}/{dataset_name}/traced_m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff792ff7-f7db-420c-b49b-e4f869980a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7911, -1.7094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences([tokenizer.tokenize(\"i hate movies\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a217a8a2-8af5-46ee-a31c-9ece74b0833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3436,  2.2181]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences([tokenizer.tokenize(\"i love movies\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b48d7e-62db-44cc-80ca-117aff2f0519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158821a3-cb7c-4170-ab2c-c480627357f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import spacy\n",
    "from anchor import anchor_text\n",
    "import pickle\n",
    "from myUtils import *\n",
    "import transformerUtils.models as models\n",
    "import transformerUtils.training as training\n",
    "import transformerUtils.plot as plot\n",
    "from transformerUtils.utils import *\n",
    "\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a1dea8-30dc-4129-b1d7-188e960b6e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3a69eb-cc30-4995-9d61-5d9326a42305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in training samples: 3307\n",
      "Number of tokens in training labels: 2\n"
     ]
    }
   ],
   "source": [
    "review_parser = None\n",
    "label_parser = None\n",
    "ds_train = None\n",
    "ds_valid = None\n",
    "ds_test = None\n",
    "\n",
    "review_parser, label_parser, ds_train, ds_valid, ds_test = create_sentiment_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f5786a-e08a-4043-968d-b6a4f49ebb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 100, 'batch_size': 32, 'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.7, 'lr': 0.0005, 'early_stopping': 5, 'output_classes': 2}\n",
      "VanillaGRU(\n",
      "  (embedding_layer): Embedding(3307, 100)\n",
      "  (GRU_layer): GRU(100, 256, num_layers=2, dropout=0.7)\n",
      "  (dropout_layer): Dropout(p=0.7, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_model('gru' , 'transformerUtils/gru_sentiment.pt', review_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4467a1be-80db-41da-a353-d24f005df72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = pad 2=sos 3 = eof \n",
    "def tokenize(text, max_len):\n",
    "    sentence = review_parser.tokenize(str(text))\n",
    "    input_tokens = [2] + [review_parser.vocab.stoi[word] for word in sentence] + [3] + [1]*(max_len-len(sentence))\n",
    "\n",
    "    return input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1f38e1-5894-4f87-8325-39144624c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(sentences):\n",
    "    half_length = len(sentences)//2\n",
    "    if(half_length>800):\n",
    "        return np.concatenate([predict_sentences(sentences[:half_length]), predict_sentences(sentences[half_length:])])\n",
    "    max_len = max([len(sentence) for sentence in sentences])\n",
    "    sentences = torch.tensor([tokenize(sentence, max_len) for sentence in sentences]).to(device)\n",
    "    input_tokens = torch.transpose(sentences, 0, 1)\n",
    "    output = model(input_tokens)\n",
    "    return torch.argmax(output, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e663df36-c570-44b0-b822-be509c30335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bea151e-3988-494f-be3f-c100b726fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_text.AnchorText(nlp, ['positive', 'negative'], use_unk_distribution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e578126-02ae-4c47-8fe0-f99bbac26f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pickle.load( open( \"results/transformer_test.pickle\", \"rb\" ))\n",
    "test_labels = pickle.load( open( \"results/transformer_test_labels.pickle\", \"rb\" ))\n",
    "test = np.array(test)\n",
    "test_labels = np.array(test_labels)\n",
    "exps= []\n",
    "#xps_file  = open( \"results/transformer_exps.pickle\", \"rb\" )\n",
    "exps  = pickle.load(open( \"results/transformer_exps_list.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e32398-2a6b-4aca-bcef-382a1c9e4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [ExtendedExplanation(exp, test, test_labels, predict_sentences, explainer) for exp in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecee4d6-5205-4b38-ac3e-afac8c842ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = [exp for exp in exps if len(exp.fit_examples) > 17] \n",
    "explanations.sort(key=lambda exp: exp.test_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e8ef03-e9c9-41da-8eb4-5b76f17d4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: wonderful\n",
      "Precision: 0.98\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 1.00\n",
      "Anchor test REAL precision: 1.00\n",
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: unexpected\n",
      "Precision: 0.97\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 1.00\n",
      "Anchor test REAL precision: 1.00\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: boring\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.97\n",
      "Anchor test REAL precision: 0.94\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: contrived\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.96\n",
      "Anchor test REAL precision: 0.79\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: stupid\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.96\n",
      "Anchor test REAL precision: 0.91\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: numbers\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.94\n",
      "Anchor test REAL precision: 0.89\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: routine\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.94\n",
      "Anchor test REAL precision: 0.94\n",
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: refreshing\n",
      "Precision: 0.96\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.94\n",
      "Anchor test REAL precision: 0.94\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: fails\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.93\n",
      "Anchor test REAL precision: 0.90\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: bore\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.93\n",
      "Anchor test REAL precision: 0.93\n",
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: best AND year\n",
      "Precision: 0.98\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.92\n",
      "Anchor test REAL precision: 0.96\n",
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: marvel\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.90\n",
      "Anchor test REAL precision: 0.90\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: silly AND .\n",
      "Precision: 0.95\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.01\n",
      "Anchor test precision: 0.89\n",
      "Anchor test REAL precision: 0.81\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: falls\n",
      "Precision: 0.98\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.01\n",
      "Anchor test precision: 0.89\n",
      "Anchor test REAL precision: 0.75\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: silly\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.01\n",
      "Anchor test precision: 0.89\n",
      "Anchor test REAL precision: 0.81\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: nothing AND about\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.89\n",
      "Anchor test REAL precision: 0.83\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: tired\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.89\n",
      "Anchor test REAL precision: 0.89\n",
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: smart AND is AND and\n",
      "Precision: 0.97\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.88\n",
      "Anchor test REAL precision: 0.92\n",
      "------------------------\n",
      "Prediction: negative\n",
      "Anchor: worst\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.01\n",
      "Anchor test precision: 0.88\n",
      "Anchor test REAL precision: 0.86\n",
      "------------------------\n",
      "Prediction: positive\n",
      "Anchor: delightful\n",
      "Precision: 0.99\n",
      "Coverage: 0.00\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test precision: 0.88\n",
      "Anchor test REAL precision: 0.92\n"
     ]
    }
   ],
   "source": [
    "filtered = [exp for exp in explanations if len(' '.join(exp.names))>3]\n",
    "best = filtered[-20:]\n",
    "best.reverse()\n",
    "for exp in best:\n",
    "    print(\"------------------------\")\n",
    "    exp_label =  predict_sentences([str(test[exp.index])])[0]\n",
    "    print('Prediction:', explainer.class_names[exp_label])\n",
    "    print('Anchor: %s' % (' AND '.join(exp.names)))\n",
    "    print('Precision: %.2f' % exp.precision)\n",
    "    print('Coverage: %.2f' % exp.coverage)\n",
    "    print('Anchor test coverage: %.2f' % (exp.test_cov))\n",
    "    print('Anchor test precision: %.2f' % exp.test_precision)\n",
    "    print('Anchor test REAL precision: %.2f' % exp.real_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc0d0678-769d-468a-8be4-140768876f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = \"\\033[1;30;41m\"\n",
    "blue = \"\\033[1;30;44m\"\n",
    "colors = {'positive': blue, \"negative\": red}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d4506-1ff0-42b9-9435-1daff7cbbdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cab98388-4e2a-4e91-a06b-42564f7b141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refreshing - positive\n",
    "sentences = [\"this is not refreshing\", \n",
    "            \"they said it's refreshing, but the opposite is true\", \n",
    "            \"i hate when people say sport is refreshing\",\n",
    "            \"refreshing at the beggining but bad afterwards\",\n",
    "            \"refreshing the page never works on this site, it is frusturating\"]\n",
    "\n",
    "#silly + . - negative\n",
    "sentences = [\"you are so silly and funny\", \n",
    "            \"this silly cat is really cute\",\n",
    "            \"your painting is not silly at all, it is very pretty.\"\n",
    "            \"that's silly, she laughed\",\n",
    "            \"that's silly, she said with a smile and laughed\"]\n",
    "\n",
    "# smart + is + and - positive\n",
    "sentences = [\"The problem is the killer is smart and quick\",\n",
    "            \"Such smart and evil person is a threat to society\",\n",
    "            \"since he is not smart and not beautiful I hate him\",\n",
    "            \"Will you still love me when I am no longer smart and beautiful ? no\",\n",
    "            \"although he is smart, he is arrogant and not kind\",\n",
    "            \"being smart and strong does not mean you can use that to hurt and make fun of others\",\n",
    "            \"it is not smart of you to sleep and do nothing all day long\",\n",
    "            \"she has low self esteem and think she is not smart\"]\n",
    "\n",
    "# unexpected - positive\n",
    "sentences= [\"The unexpected information was coming so fast it was hard to absorb\",\n",
    "           \"I dont like when an unexpected guest arrives\",\n",
    "           \"She wanted nothing to do with this world or its inhabitants, despite that unexpected, intimate connection with him\",\n",
    "           \"The king's demise and empire falling apart was unexpected\",\n",
    "           \"However, players can be cruelly exposed whenever a ball or opponent does something unexpected\",\n",
    "           \"his death was unexpected\",\n",
    "           \"his death was traumatic and unexpected\",\n",
    "           \"The unexpected earthquake was a disaster\",\n",
    "           \"The unexpected earthquake was a terrible disaster\"]\n",
    "\n",
    "#boring - negative\n",
    "sentences = [\"A commitment to green living definitely doesn't mean being boring, on the contrary, a Tesla car is at the cutting edge of both environmentalism and style\",\n",
    "            \"Going green and leading a more environmentally friendly lifestyle need not be dull and boring\",\n",
    "            \"It's easy to turn a boring, sterile-looking dorm room into a comfortable and stylish living space\",\n",
    "            \"Some people think that white is boring, but over the years it has consistently been a popular and pretty color choice for kitchens\",\n",
    "            \"sometimes a boring day can be relaxing and good for your health\",\n",
    "            \"I do not think your idea is boring, it is interesting and I love it\",\n",
    "            \"The painting is the total opposite from boring, being very colorful and cheerful\"] \n",
    "\n",
    "# numbers - negative\n",
    "sentences = [\"Their numbers are far greater than anything we ever imagined, amazing !\",\n",
    "            \"I am very good with numbers\",\n",
    "            \"He won the prize, his numbers were correct\",\n",
    "            \"I enjoy working with numbers now and then\",\n",
    "            \"The nation's greater numbers enabled it to outflank the enemy and win the battle\",\n",
    "            \"Their power and success are in numbers\",\n",
    "            \"She loves calculating numbers since a very young age\"\n",
    "            \"She loves calculating numbers since a very young age, it makes her happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f67d5083-6762-4e45-a70d-6edcfee56c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68b2b45f-9b18-4be9-a360-52685f906bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [explainer.class_names[exp_label] for exp_label in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0b9bcaa-31a4-4324-96e1-0873b7af8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_exps = [text for text, label in zip(sentences, labels) if label =='positive']\n",
    "neg_exps = [text for text, label in zip(sentences, labels) if label =='negative']\n",
    "examples = {'positive': pos_exps, \"negative\": neg_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "337320bf-f3f2-45fb-aef3-2f18490eec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;44mpositive \n",
      "\n",
      "\u001b[1;30;44mI enjoy working with numbers now and then \n",
      "\n",
      "\u001b[1;30;44mShe loves calculating numbers since a very young ageShe loves calculating numbers since a very young age, it makes her happy \n",
      "\n",
      "\u001b[1;30;41mnegative \n",
      "\n",
      "\u001b[1;30;41mTheir numbers are far greater than anything we ever imagined, amazing ! \n",
      "\n",
      "\u001b[1;30;41mI am very good with numbers \n",
      "\n",
      "\u001b[1;30;41mHe won the prize, his numbers were correct \n",
      "\n",
      "\u001b[1;30;41mThe nation's greater numbers enabled it to outflank the enemy and win the battle \n",
      "\n",
      "\u001b[1;30;41mTheir power and success are in numbers \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for exp_type in examples.keys():\n",
    "    print(colors[exp_type] + exp_type+ ' \\n')\n",
    "    for sentence in examples[exp_type]:\n",
    "        print(colors[exp_type]+sentence + ' \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acbd4dc-f69a-45f6-b66a-86e2c9c0f27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835a9cb-0fbf-490a-bc59-d1c2a3aea785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

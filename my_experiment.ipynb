{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "from numba import jit\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "This dataset is about predicting if a person makes more or less than 50,000 dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have adult/adult.data inside dataset_folder\n",
    "dataset_folder = '.'\n",
    "dataset = utils.load_dataset('adult', balance=True, dataset_folder=dataset_folder, discretize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a classifier for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9350338780390594\n",
      "Test 0.8489483747609943\n"
     ]
    }
   ],
   "source": [
    "c = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "c.fit(dataset.train, dataset.labels_train)\n",
    "print('Train', sklearn.metrics.accuracy_score(dataset.labels_train, c.predict(dataset.train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(dataset.labels_test, c.predict(dataset.test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start the explainer. We need the training data to perturb instances.\n",
    "`categorical_names` is a map from integer to list of strings, containing names for each\n",
    "            value of the categorical features. Every feature that is not in\n",
    "            this map will be considered as ordinal or continuous, and thus discretized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    dataset.class_names,\n",
    "    dataset.feature_names,\n",
    "    dataset.train,\n",
    "    dataset.categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyExplenation:\n",
    "    def __init__(self, index, fit_examples, test_cov, exp):\n",
    "        self.index = index\n",
    "        self.fit_examples = fit_examples\n",
    "        self.test_cov = test_cov\n",
    "        self.names =  exp.names()\n",
    "        self.coverage = exp.coverage()\n",
    "        self.precision = exp.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we get an anchor for prediction number 0. An anchor is a sufficient condition - that is, when the anchor holds, the prediction should be the same as the prediction for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp(idx):\n",
    "    return explainer.explain_instance(dataset.test[idx], c.predict, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit_examples(exp, idx):\n",
    "    return np.where(np.all(dataset.test[:, exp.features()] == dataset.test[idx][exp.features()], axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_cov(fit_anchor):\n",
    "    return (fit_anchor.shape[0] / float(dataset.test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(explenations):\n",
    "    exps_names = [' AND '.join(exp.names) for exp in explenations]\n",
    "    seen = set()\n",
    "    saved_exps = list()\n",
    "    for i, exp in enumerate(explenations):\n",
    "        if exps_names[i] not in seen:\n",
    "            saved_exps.append(exp)\n",
    "        seen.add(exps_names[i])\n",
    "    \n",
    "    return saved_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_explenations(indices):\n",
    "    length = len(indices)\n",
    "    explenations = list()\n",
    "    for i, index in enumerate(indices):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        cur_exp = get_exp(index)\n",
    "        cur_fit = get_fit_examples(cur_exp, index)\n",
    "        cur_test_cov = get_test_cov(cur_fit)\n",
    "        \n",
    "        explenations.append(MyExplenation(index, cur_fit, cur_test_cov, cur_exp))\n",
    "    \n",
    "    return remove_duplicates(explenations)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "exps_num = 300\n",
    "explenations = compute_explenations(np.random.choice(len(dataset.test), exps_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( explenations, open( \"exps.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "explenations = pickle.load( open( \"exps.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "explenations.sort(key=lambda exp: exp.test_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Anchor: Relationship = Not-in-family AND Marital Status = Divorced AND Hours per week <= 40.00 AND Capital Gain = 0 AND Education = Some-college\n",
      "Precision: 0.96\n",
      "Coverage: 0.01\n",
      "Anchor test precision: 0.83\n",
      "Anchor test coverage: 0.00\n",
      "Anchor test REAL precision: 0.83\n",
      "------------------------\n",
      "Anchor: Age <= 28.00 AND Marital Status = Never-married AND Education = HS-grad\n",
      "Precision: 1.00\n",
      "Coverage: 0.03\n",
      "Anchor test precision: 1.00\n",
      "Anchor test coverage: 0.04\n",
      "Anchor test REAL precision: 1.00\n"
     ]
    }
   ],
   "source": [
    "best = explenations[-10:]\n",
    "for exp in best:\n",
    "    print(\"------------------------\")\n",
    "    exp_label =  c.predict(dataset.test[exp.index].reshape(1, -1))\n",
    "    print('Anchor: %s' % (' AND '.join(exp.names)))\n",
    "    print('Precision: %.2f' % exp.precision)\n",
    "    print('Coverage: %.2f' % exp.coverage)\n",
    "    print('Anchor test precision: %.2f' % (np.mean(c.predict(dataset.test[exp.fit_examples]) == exp_label)))\n",
    "    print('Anchor test coverage: %.2f' % (exp.test_cov))\n",
    "    covered_labels = dataset.labels_test[exp.fit_examples]\n",
    "    real_percentage = np.mean(covered_labels == exp_label)\n",
    "    print('Anchor test REAL precision: %.2f' % real_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  b'>50K'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "np.random.seed(1)\n",
    "print('Prediction: ', explainer.class_names[c.predict(dataset.test[idx].reshape(1, -1))[0]])\n",
    "exp = explainer.explain_instance(dataset.test[idx], c.predict, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Education = Bachelors AND Relationship = Husband AND Marital Status = Married-civ-spouse AND Occupation = Sales AND Race = White\n",
      "Precision: 0.96\n",
      "Coverage: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set threshold to 0.95, so we guarantee (with high probability) that precision will be above 0.95 - that is, that predictions on instances where the anchor holds will be the same as the original prediction at least 95% of the time. Let's try it out on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor test precision: 0.97\n",
      "Anchor test coverage: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Get test examples where the anchora pplies\n",
    "fit_anchor = np.where(np.all(dataset.test[:, exp.features()] == dataset.test[idx][exp.features()], axis=1))[0]\n",
    "print('Anchor test precision: %.2f' % (np.mean(c.predict(dataset.test[fit_anchor]) == c.predict(dataset.test[idx].reshape(1, -1)))))\n",
    "print('Anchor test coverage: %.2f' % (fit_anchor.shape[0] / float(dataset.test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

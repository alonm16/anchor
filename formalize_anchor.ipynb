{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5073ae0a-f2d7-4f9e-95c1-3353fef4304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import spacy\n",
    "from orig_anchor import anchor_text\n",
    "import pickle\n",
    "from myUtils import *\n",
    "from transformer.utils import *\n",
    "from dataset.dataset_loader import *\n",
    "import datetime\n",
    "\n",
    "SEED = 84\n",
    "torch.manual_seed(SEED)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07fc3de-eb19-4f46-bb94-6ad8a334e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2444c8e5-2a8b-4797-9248-46565487f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19190\n",
      "4163\n",
      "Number of tokens in training samples: 6230\n",
      "Number of tokens in training labels: 2\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'offensive'\n",
    "review_parser, label_parser, ds_train, ds_val = offensive_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "153fa98e-e8bc-4543-8f98-e5fde929cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 100, 'batch_size': 32, 'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.3, 'lr': 5e-05, 'early_stopping': 5, 'output_classes': 2}\n",
      "VanillaGRU(\n",
      "  (embedding_layer): Embedding(6230, 100)\n",
      "  (GRU_layer): GRU(100, 256, num_layers=2, dropout=0.3)\n",
      "  (dropout_layer): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_model('gru' , f'transformer/{dataset_name}/gru.pt', review_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459d3230-e32a-435c-a0eb-b52ccf07133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = pad 2=sos 3 = eos\n",
    "def tokenize(text, max_len):\n",
    "    sentence = review_parser.tokenize(str(text))\n",
    "    input_tokens = [2] + [review_parser.vocab.stoi[word] for word in sentence] + [3] + [1]*(max_len-len(sentence))\n",
    "\n",
    "    return input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f77028-4510-4882-aa43-847c91ab3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(sentences):\n",
    "    half_length = len(sentences)//2\n",
    "    if(half_length>100):\n",
    "        return np.concatenate([predict_sentences(sentences[:half_length]), predict_sentences(sentences[half_length:])])\n",
    "    max_len = max([len(sentence) for sentence in sentences])\n",
    "    sentences = torch.tensor([tokenize(sentence, max_len) for sentence in sentences]).to(device)\n",
    "    input_tokens = torch.transpose(sentences, 0, 1)\n",
    "    output = model(input_tokens)\n",
    "\n",
    "    return torch.argmax(output, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ae844-8cfc-48c9-b46f-c41106d4dd8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Anchor Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da1181f-98b5-4f15-9896-d4a99cf231be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c976b285-caee-439e-870d-a43850a4551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_text.AnchorText(nlp, ['positive', 'negative'], use_unk_distribution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74e7fe-f7b1-4544-b3f6-5485e00a9ecc",
   "metadata": {},
   "source": [
    "# Loading Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2781ed-fb71-478e-9d30-e393c645b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(pickle.load( open(  f\"{dataset_name}/test.pickle\", \"rb\" )))\n",
    "test_labels = np.array(pickle.load( open(  f\"{dataset_name}/test_labels.pickle\", \"rb\" )))\n",
    "\n",
    "explanations  = pickle.load(open(  f\"{dataset_name}/exps_list.pickle\", \"rb\" ))\n",
    "anchor_examples = pickle.load( open(  f\"{dataset_name}/anchor_examples.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a5f566-1476-4b96-b5f9-2366fd83f0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2419"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchor_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0157d1c2-7146-4945-9c93-30f1d2a12151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25137"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d016697b-8209-421d-ba40-757a82b8ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.array([predict_sentences([text])[0] for text in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9b278ed-8174-4650-922a-d12cc6c5d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = [ExtendedExplanation(exp, anchor_examples, test, test_labels, test_predictions ,predict_sentences, explainer) for exp in explanations if len(exp.fit_examples) > 0]\n",
    "pickle.dump( explanations, open(  f\"{dataset_name}/extended_exps.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2037c3-892c-468a-b14f-a31f47c765ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = pickle.load(open(  f\"{dataset_name}/extended_exps.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf8368d-4154-4bdb-bd79-017fd65aa076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best anchor of each anchor example, it is the chosen anchor\n",
    "def get_best(explanations):\n",
    "    best_exps = dict()\n",
    "    for exp in explanations:\n",
    "        if exp.index not in best_exps.keys():\n",
    "            best_exps[exp.index]=exp\n",
    "        elif exp.precision > best_exps[exp.index].precision:\n",
    "            best_exps[exp.index]=exp\n",
    "    return best_exps.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60535acf-32f9-4729-9596-eaf3953b39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "def calculate_teta0(anchor_examples):\n",
    "    num_words = sum(len(example) for example in anchor_examples)\n",
    "    c = Counter()\n",
    "    for example in anchor_examples:\n",
    "        c.update(review_parser.tokenize(example))\n",
    "    for word in c.keys():\n",
    "        c[word] = c[word]/ num_words\n",
    "    return c\n",
    "\n",
    "def calculate_p_anchor(explanations):\n",
    "    c = Counter()\n",
    "    for exp in explanations:\n",
    "        c.update([exp.names[0]])\n",
    " \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53dc72a3-710e-4e17-b439-19e0f65b3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_formula(exps, teta0, alpha = 0.95):\n",
    "    teta1 = dict()\n",
    "    p_anchor = calculate_p_anchor(exps)\n",
    "    for anchor in p_anchor.keys():\n",
    "        teta1[anchor] = (p_anchor[anchor]/len(exps) - (1-alpha)*teta0[anchor])/alpha\n",
    "    return teta1, p_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fed10a2b-6b83-4495-ae01-3f2ceda2dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores():\n",
    "    alphas = [0.15, 0.35, 0.55, 0.75, 0.95]\n",
    "    exps = get_best(explanations)\n",
    "    teta0 = calculate_teta0(anchor_examples)\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        scores, counter = calculate_formula(exps, teta0, alpha)\n",
    "        df_list = []\n",
    "       \n",
    "        for anchor, score in scores.items():\n",
    "            df_list.append([anchor, score ,counter[anchor]]) \n",
    "\n",
    "        df_list.sort(key=lambda exp: -exp[1])\n",
    "        df = pd.DataFrame(data = df_list, columns = ['name', 'score', 'num anchors']).set_index('name')\n",
    "        df.to_csv( f'{dataset_name}/formalized_scores_{alpha}.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ae53ce-91e5-4f7a-8f46-256b4c6c9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_double():\n",
    "    alphas = [0.15, 0.35, 0.55, 0.75, 0.95]\n",
    "    labels = [predict_sentences([str(anchor_example)])[0] for anchor_example in anchor_examples]\n",
    "    exps = get_best(explanations)\n",
    "    teta0 = calculate_teta0(anchor_examples)\n",
    "    \n",
    "    pos_exps = [exp for exp in exps if labels[exp.index]==0]\n",
    "    neg_exps = [exp for exp in exps if labels[exp.index]==1]\n",
    "    \n",
    "    \n",
    "    for alpha in alphas:\n",
    "        df_list = []\n",
    "        pos_scores, pos_counter = calculate_formula(pos_exps, teta0, alpha)\n",
    "        neg_scores, neg_counter = calculate_formula(neg_exps, teta0, alpha)\n",
    "        \n",
    "        for anchor, score in pos_scores.items():\n",
    "            pos_percent = pos_counter[anchor]/(pos_counter[anchor]+neg_counter[anchor])\n",
    "            neg_percent = 1-pos_percent\n",
    "            both = pos_counter[anchor]>0 and neg_counter[anchor]>0\n",
    "            df_list.append([anchor, score , '+', pos_counter[anchor], pos_counter[anchor]+ neg_counter[anchor],pos_percent, neg_percent, both]) \n",
    "            \n",
    "        \n",
    "        for anchor, score in neg_scores.items():\n",
    "            pos_percent = pos_counter[anchor]/(pos_counter[anchor]+neg_counter[anchor])\n",
    "            neg_percent = 1-pos_percent\n",
    "            both = pos_counter[anchor]>0 and neg_counter[anchor]>0\n",
    "            df_list.append([anchor, score , '-', neg_counter[anchor], pos_counter[anchor]+ neg_counter[anchor],pos_percent, neg_percent, both]) \n",
    "\n",
    "        df_list.sort(key=lambda exp: -exp[1])\n",
    "        df = pd.DataFrame(data = df_list, columns = ['name', 'score', 'label', 'num anchors', 'total', 'pos%', '%neg%', 'both']).set_index('name')\n",
    "        df.to_csv( f'{dataset_name}/formalized_scores_double_{alpha}.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "245d0db5-007c-4b77-83bc-dd588c65fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_scores_double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ffaac87-868c-4d9b-ace1-430de97b4125",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teta1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5414/817841442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteta1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteta1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'teta1' is not defined"
     ]
    }
   ],
   "source": [
    "x=sum(teta1.values())/len(teta1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06d28b-6373-4b98-aa36-1983f56fa6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sum(teta0.values())/len(teta0.keys())\n",
    "x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af0994-8ebf-445e-94c6-1899070214c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c0ebe-85fa-4747-a709-6bebef07447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = [exp for exp in explanations if len(exp.fit_examples) > 10] \n",
    "explanations.sort(key=lambda exp: exp.test_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2581016-4483-46a2-95b2-3dde8f5d823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [exp for exp in explanations if len(' '.join(exp.names))>=4]\n",
    "best = filtered[-10:]\n",
    "best.reverse()\n",
    "for exp in best:\n",
    "    print(\"------------------------\")\n",
    "    exp_label =  predict_sentences([str(anchor_examples[exp.index])])[0]\n",
    "    print('Prediction:', explainer.class_names[exp_label])\n",
    "    print('Anchor: %s' % (' AND '.join(exp.names)))\n",
    "    print('Precision: %.2f' % exp.precision)\n",
    "    print('Coverage: %.2f' % exp.coverage)\n",
    "    print('Anchor test precision: %.2f' % exp.test_precision)\n",
    "    print('Anchor test coverage: %.2f' % (exp.test_cov))\n",
    "    covered_labels = counter_test_labels[exp.fit_examples]\n",
    "    \n",
    "    print('Anchor test REAL precision: %.2f' % exp.real_precision)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f47d1-1faa-4a73-9d86-b1bbd7a9b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = explanations[len(explanations)//2:]\n",
    "exps = [exp for exp in exps if len(exp.fit_examples)>10]\n",
    "#trained model has the opposite label\n",
    "real_precisions = [exp.real_precision for exp in exps]\n",
    "test_precisions = [exp.test_precision for exp in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076539d-1a41-4388-b5bf-c6bc0db9e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_precisions, real_precisions, s = range(len(exps)), alpha = 0.5)\n",
    "plt.xlabel('predicted precision')\n",
    "plt.ylabel('label precision')\n",
    "plt.title('LSTM')\n",
    "plt.savefig(\"results/spam.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149119b-0d56-46b5-ae15-38d1b6b9fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"results/gru_on_counter.png\")\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.axis('off')\n",
    "_ = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc02d86-59e5-43d2-8d18-9bdfde7e9bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
